{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyz6MPL4AIF1Swpe3o+yKT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PDecXj2_RHN","executionInfo":{"status":"ok","timestamp":1761456630519,"user_tz":-330,"elapsed":27564,"user":{"displayName":"Guna Sekhar","userId":"02678491187712962059"}},"outputId":"ffe73e1d-552a-4e7f-fdbc-4da25c650174"},"outputs":[{"output_type":"stream","name":"stdout","text":["i=  2   Change of Lables=   0.23682864450127872\n","i=  3   Change of Lables=   0.17391304347826086\n","i=  4   Change of Lables=   0.09309462915601019\n","i=  5   Change of Lables=   0.03887468030690533\n","i=  6   Change of Lables=   0.012787723785166238\n","i=  7   Change of Lables=   0.00358056265984652\n","i=  8   Change of Lables=   0.000511508951406614\n","i=  9   Change of Lables=   0.0\n","\n","Testing:\n","\n","Accuracy on the test data:  0.5862068965517241\n"]}],"source":["from sklearn.datasets import fetch_20newsgroups\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","from sklearn.feature_extraction.text import CountVectorizer\n","import numpy as np\n","import re\n","from sklearn.linear_model import LogisticRegression\n","\n","classes = ['sci.med', 'rec.motorcycles', 'talk.politics.guns']\n","newsgroups = fetch_20newsgroups(subset='all', shuffle=True, categories=classes)\n","\n","def extract_body(text):\n","    # Split on first empty line (headers end)\n","    parts = re.split(r'\\n\\s*\\n', text, maxsplit=1)\n","    return parts[1] if len(parts) > 1 else text  # Return body only\n","\n","# Apply to all documents\n","cleaned_data = [extract_body(doc) for doc in newsgroups.data]\n","labels = newsgroups.target\n","\n","# spliting test and train\n","X_train, X_test, y_train, y_test = train_test_split(cleaned_data, labels, test_size=0.1)\n","\n","# splitting training data to labled and unlabled\n","X_train_labled, X_train_unlabled, y_train_labled, dummy = train_test_split(X_train, y_train, test_size=0.75)\n","\n","# Create a CountVectorizer (BoW model)\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n","\n","# Fit and transform the labled training data\n","X_train_labled = count_vectorizer.fit_transform(X_train_labled)\n","\n","# Fit and transform the labled training data\n","X_train_unlabled = count_vectorizer.fit_transform(X_train_unlabled)\n","\n","# Transform the test data\n","X_test = count_vectorizer.transform(X_test)\n","#Training Starts...\n","#model = LogisticRegression(max_iter=1000)\n","model = MultinomialNB()\n","model.fit(X_train_labled, y_train_labled) #model 0\n","\n","for i in range(1,100):\n","  y_train_unlabled = model.predict(X_train_unlabled)\n","  #print('Accuracy on the unlabled prediction: ',accuracy_score(dummy, y_train_unlabled))\n","  if(i>1):\n","    print('i= ',i,'  Change of Lables=  ',1-accuracy_score(y_train_unlabled, y_train_unlabled_previous))\n","    if(accuracy_score(y_train_unlabled, y_train_unlabled_previous)>0.99999):\n","      break\n","  y_train_unlabled_previous = y_train_unlabled\n","  X_combined = np.vstack([X_train_labled.toarray(), X_train_unlabled.toarray()])\n","  y_combined = np.concatenate([y_train_labled, y_train_unlabled])\n","\n","  # Retrain the model on the combined data\n","  model.fit(X_combined, y_combined)  #i th model\n","\n","#testing\n","print('\\nTesting:\\n')\n","print('Accuracy on the test data: ',accuracy_score(y_test, model.predict(X_test)))"]}]}